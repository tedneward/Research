title=AI
category=ai
type=categorypage
summary=A collection of links around artificial intelligence (and all the different permutations of that phrase).
tags=ai, machine learning, fuzzy logic, logic, expert system, nlp
~~~~~~

## Uncategorized (yet)

## General

- [The 10+1 Commandments of Human AI Co-Existence](https://10plus1.ai/): "The 10+1 is a standard. Not everyone will adopt it - but those who do will lead the next era. If you're a policymaker, don't wait for regulation to catch up. If you're a CEO, don't wait for PR fallout to act with integrity. If you're building AI, don't just ask if it works - ask if it's worthy. We don't need more frameworks. We need a philosophical backbone. This is it."
- [AI Defeats the Purpose of a Humanities Education](https://www.thecrimson.com/article/2025/9/9/chiocco-farrell-harvard-ai/) (The Harvard Crimson)
- ["The Open-Source Toolkit for Building AI agents"](https://www.aitidbits.ai/p/open-source-agents)
- [Is Complexity an Illusion?](https://arxiv.org/pdf/2404.07227): "Simplicity is held by many to be the key to general intelligence. Simpler models tend to “generalise”, identifying the cause or generator of data with greater sample efficiency. The implications of the correlation between simplicity and generalisation extend far beyond computer science, addressing questions of physics and even biology. Yet simplicity is a property of form, while generalisation is of function. In interactive settings, any correlation between the two depends on interpretation. In theory there could be no correlation and yet in practice, there is. Previous theoretical work showed generalisation to be a consequence of “weak” constraints implied by function, not form. Experiments demonstrated choosing weak constraints over simple forms yielded a 110 − 500% improvement in generalisation rate. Here we show that all constraints can take equally simple forms, regardless of weakness. However if forms are spatially extended, then function is represented using a finite subset of forms. If function is represented using a finite subset of forms, then we can force a correlation between simplicity and generalisation by making weak constraints take simple forms. If function is determined by a goal directed process that favours versatility (e.g. natural selection), then efficiency demands weak constraints take simple forms. Complexity has no causal influence on generalisation, but appears to due to confounding."
- Rob Conery's posts exploring using AI in a dev setting:

    - ["Using Gemini CLI to Learn Something New"](https://thenext.dev/articles/all/using-gemini-cli-to-learn-something-new/)
    - ["Creating a Markdown Compiler"](https://thenext.dev/articles/copilot/creating-a-markdown-compiler/) (video)
    - ["Turning a Markdown Spec into a Database - With Test Data!"](https://thenext.dev/articles/video/turning-a-markdown-spec-into-a-database-with-test-data/)

- ["You're Building AI Apps Backwards: The Model-Product Problem"](https://thenewstack.io/youre-building-ai-apps-backwards-the-model-product-problem/)
- ["AI Models Need a Virtual Machine"](https://blog.sigplan.org/2025/08/29/ai-models-need-a-virtual-machine/)
- [Artificial Intelligence for a Better Future: An Ecosystem Perspective on the Ethics of AI and Emerging Digital Technologies](https://link.springer.com/book/10.1007/978-3-030-69978-9) - Bernd Carsten Stahl (PDF)
- [Artificial Intelligence: Foundations of Computational Agents (2017), 2nd Edition](https://artint.info) - David L. Poole, Alan K. Mackworth @ Cambridge University Press (HTML, Slides)
- [Artificial Intelligence: Foundations of Computational Agents (2010), 1st Edition](https://artint.info/aifca1e.html) - David L. Poole, Alan K. Mackworth @ Cambridge University Press (HTML)
- [Deep Learning](https://issuu.com/cmb321/docs/deep_learning_ebook?ff)
- [Introduction to Autonomous Robots](https://github.com/correll/Introduction-to-Autonomous-Robots/releases) - Nikolaus Correll (PDF)
- [On the Path to AI: Law’s prophecies and the conceptual foundations of the machine learning age](https://link.springer.com/book/10.1007/978-3-030-43582-0) - Thomas D. Grant, Damon J. Wischik (PDF)
- [Probabilistic Programming & Bayesian Methods for Hackers](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/) - Cam Davidson-Pilon (HTML, Jupyter Notebook)

## History

- [The Quest for Artificial Intelligence: A History of Ideas and Achievements](http://ai.stanford.edu/~nilsson/QAI/qai.pdf) - Nils J. Nilsson (PDF)

## Criticism

- [AI Underpants Gnomes: The Missing Step in Your Strategy](https://www.jsnover.com/blog/2025/11/18/ai-underpants-gnomes-the-missing-step-in-your-strategy/)
- ["The Copilot Delusion"](https://deplet.ing/the-copilot-delusion/)
- [The Hidden Costs of Coding With Generative AI](https://sloanreview.mit.edu/article/the-hidden-costs-of-coding-with-generative-ai/)
- [The Hidden Costs of AI Coding Assistants: Insights from a Senior Developer](https://blog.devgenius.io/the-hidden-costs-of-ai-coding-assistants-insights-from-a-senior-developer-76274fe6b345)
- ["My new hobby: watching AI slowly drive Microsoft employees insane"](https://www.reddit.com/r/ExperiencedDevs/comments/1krttqo/my_new_hobby_watching_ai_slowly_drive_microsoft/)
- Where's Your Ed At?

    - [Reality Check](https://www.wheresyoured.at/reality-check/)
    - [AI Bubble 2027](https://www.wheresyoured.at/ai-bubble-2027/)
    - [How to Argue with an AI Booster](https://www.wheresyoured.at/how-to-argue-with-an-ai-booster/)
    - [The Haters Guide to The AI Bubble](https://www.wheresyoured.at/the-haters-gui/)
    - [Pop Culture](https://www.wheresyoured.at/pop-culture/)

- [We need to stop pretending AI is intelligent -- here's how](https://theconversation.com/we-need-to-stop-pretending-ai-is-intelligent-heres-how-254090)
- [AI: Not That Smart](https://columbiacommunityconnection.com/the-dalles/column-ai-not-that-smart)
- [Building AI Products In The Probabilistic Era](https://giansegato.com/essays/probabilistic-era): "Just as physics underwent a conceptual revolution when we moved past Newton's deterministic universe, and into a strange and counterintuitive place made by wave functions, software too is undergoing its own quantum shift. We're leaving a world where code reliably and deterministically takes certain inputs to produce specific outputs, and entering a very different one where machines now produce statistical distributions instead. *Building probabilistic software is like nothing we've done before.*"
- ["AI coding tools make developers slower but they think they're faster, study finds"](https://www.theregister.com/2025/07/11/ai_code_tools_slow_down/)
- [Measuring the Impact of Early-2025 AI on Experienced Open-Source Developer Productivity](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/): "We conduct a randomized controlled trial (RCT) to understand how early-2025 AI tools affect the productivity of experienced open-source developers working on their own repositories. Surprisingly, we find that when developers use AI tools, they take 19% longer than without—AI makes them slower. We view this result as a snapshot of early-2025 AI capabilities in one relevant setting; as these systems continue to rapidly evolve, we plan on continuing to use this methodology to help estimate AI acceleration from AI R&D automation." ([full paper](https://arxiv.org/abs/2507.09089))

    - **Methodology**: To directly measure the real-world impact of AI tools on software development, we recruited 16 experienced developers from large open-source repositories (averaging 22k+ stars and 1M+ lines of code) that they’ve contributed to for multiple years. Developers provide lists of real issues (246 total) that would be valuable to the repository—bug fixes, features, and refactors that would normally be part of their regular work. Then, we randomly assign each issue to either allow or disallow use of AI while working on the issue. When AI is allowed, developers can use any tools they choose (primarily Cursor Pro with Claude 3.5/3.7 Sonnet—frontier models at the time of the study); when disallowed, they work without generative AI assistance. Developers complete these tasks (which average two hours each) while recording their screens, then self-report the total implementation time they needed. We pay developers $150/hr as compensation for their participation in the study.
    - **Core Result**: When developers are allowed to use AI tools, they take 19% longer to complete issues—a significant slowdown that goes against developer beliefs and expert forecasts. This gap between perception and reality is striking: developers expected AI to speed them up by 24%, and even after experiencing the slowdown, they still believed AI had sped them up by 20%. Below, we show the raw average developer forecasted times, and the observed implementation times—we can clearly see that developers take substantially longer when they are allowed to use AI tools.
    - **Clarifications**: We list claims that we do not provide evidence for:

        We do not provide evidence that: | Clarification
        -------------------------------- | -------------
        AI systems do not currently speed up many or most software developers | We do not claim that our developers or repositories represent a majority or plurality of software development work
        AI systems do not speed up individuals or groups in domains other than software development | We only study software development
        AI systems in the near future will not speed up developers in our exact setting | Progress is difficult to predict, and there has been substantial AI progress over the past five years [3]
        There are not ways of using existing AI systems more effectively to achieve positive speedup in our exact setting | Cursor does not sample many tokens from LLMs, it may not use optimal prompting/scaffolding, and domain/repository-specific training/finetuning/few-shot learning could yield positive speedup

    - **Factor Analysis**: We investigate 20 potential factors that might explain the slowdown, finding evidence that 5 likely contribute:


        We rule out many experimental artifacts—developers used frontier models, complied with their treatment assignment, didn’t differentially drop issues (e.g. dropping hard AI-disallowed issues, reducing the average AI-disallowed difficulty), and submitted similar quality PRs with and without AI. The slowdown persists across different outcome measures, estimator methodologies, and many other subsets/analyses of our data. See the paper for further details and analysis.

    - **FAQs**:

        - *How were developers actually slowed down given they had the option to not use AI?* After the study, developers estimated that they were sped up by 20% on average when using AI--so they were mistaken about AI’s impact on their productivity. Furthermore, it’s possible that developers use AI tools for reasons other than pure productivity--for example, they may find it a more pleasant/enjoyable experience, or they may view it as an investment into learning skills that they expect to be useful with future (more capable) systems.
        - *What was the motivation for this study? Were we incentivized/motivated to find this result?* METR is a non-profit (funded by donations) interested in understanding how close AI systems are to accelerating the AI R&D process, which could pose significant destabilizing risks [1]. This study was designed to give us evidence about a similar domain: experienced, open-source developers working on projects they’re highly familiar with. We initially were broadly expecting to see positive speedup—scientific integrity is a core value of ours, and we were (and are) committed to sharing results regardless of the outcome.
        - *You only had 16 developers, so these results will not generalize/replicate.* We compute confidence intervals accounting for the number of developers by using clustered standard errors (not reported in the released paper, but forthcoming). Because we don’t observe meaningful within-developer structure, and each developer completes issues in both conditions, the 246 total completed issues give us (just enough) sufficient statistical power to reject the null hypothesis of zero speedup/slowdown. See Appendix D for discussion of our empirical strategy. There is still a question of representativeness—i.e. there are likely biases in which developers ended up participating in the study. For example, there may be experienced, open-source developers who decided to not participate because they believe they have significant positive speedup from AI, and they didn’t want to be forced to not use AI on 50% of their tasks. No developer reports thinking in this way, but we can’t rule this (or other sampling biases) out.
        - *Are the developers beginners at using Cursor/AI tools? Does this explain the result?* Developers seem to be qualitatively in-distribution for Cursor Pro users, although we can’t rule out learning effects beyond 50 hours of Cursor usage. Nearly all developers have substantial (dozens to hundreds of hours) prior experience prompting LLMs. See Appendix C.2.7 for more discussion/analysis of developer AI tool use skill.
        - *Do these results say that AI isn't useful in software engineering?* No--it seems plausible or likely that AI tools are useful in many other contexts different from our setting, for example, for less experienced developers, or for developers working in an unfamiliar codebase. See Appendix B for potential misreadings/overgeneralizations we do not endorse on the basis of our results.
        - *It's not appropriate to use homoskedastic SEs. What gives?* Appendix C.3.5 explores alternative estimators, including a naive ratio estimator. All alternative estimators evaluated yield similar results, suggesting that the slowdown result is robust to our empirical strategy. That said, we are actively evaluating further standard error estimation methods, in response to community feedback (thank you to those who have given feedback so far!).

- AI Anthropomorphism

    - [Why do Humans Anthropomorphize AI?](https://www.sciencefriday.com/segments/ai-human-personification/)
    - [Are You ...?](https://blog.apaonline.org/2024/08/20/are-you-anthropomorphizing-ai-2/)
    - [We need to stop ...](https://www.reddit.com/r/singularity/comments/1845l4p/we_need_to_stop_anthropomorphizing_ai/)
    - [The Four Degrees of ...](https://www.nngroup.com/articles/anthropomorphism/)
    - [Why Human-like is not human](https://www.copyright.com/blog/anthropomorphizing-ai-why-human-like-is-not-human/)
    - [Anthropomorphism and AI: hype and fallacy](https://link.springer.com/article/10.1007/s43681-024-00419-4) ([PDF](../s43681-024-00419-4.pdf)): "As a form of hype, anthropomorphism is shown to exaggerate AI capabilities and performance by attributing human-like traits to systems that do not possess them. As a fallacy, anthropomorphism is shown to distort moral judgments about AI, such as those concerning its moral character and status, as well as judgments of responsibility and trust. By focusing on these two dimensions of anthropomorphism in AI, the essay highlights negative ethical consequences of the phenomenon in this field."
    - [A Vaccine](https://commoncog.com/vaccine-anthropomorphism-of-ai/): "Here is an explanation that I finally settled on, based on a tweet by prominent AI researcher and educator Andrej Karpathy. When I first tried it out on my dad, he kept quiet for a little bit, and then shifted the way he saw and used LLMs. I’ve tested this on a few friends since, of varying levels of technical sophistication, and am pleased to report that it works quite well. This explanation is useful but not accurate. I’ll give you the explanation, explain why it works, and then give a brief sketch on how it is not true. Finally, I’ll argue that even if it is not accurate, this explanation points you towards more productive mental models of LLMs.
        1. "Imagine that you can visualise words like stars in the sky. The position of the words relative to other words are based on the relationships between each of the words in your language (that is: how closely and how frequently a word appears next to another word in all the sentences ever written). What is important to know is that you can draw arrows from one star to another! These arrows have some surprising properties. One property is that the arrow from the word ‘king’ to the word ‘queen’ is the same as ‘king - boy + girl’. On top of that, let’s imagine that you throw up a starfield for English and a starfield for Spanish. It turns out that if you can draw a one-to-one mapping between the two starfields, the king to queen arrow is the same in both languages! This was a very surprising finding when it first came out!
        2. " What a Large Language Model is is that it is a very sophisticated auto complete. But it is a bit more than that.
        3. "When you ask “what are the 10 best places to visit in Bali” the AI will give you a plausible-sounding answer. But the way it gives you that answer is that during the AI’s training, some human somewhere wrote an answer like “the top 10 places to visit in London” and “the top 10 places to visit in Tokyo” and “the top 10 places to visit in New York” based on some cursory research and Google searches. Then the AI took those written examples, and memorised the statistical relationships between the sentences, which you can imagine like the arrows between large clusters of stars. Then when you ask “what are the 10 best places in Bali or Singapore or Lisbon”, it just moves the arrows it learnt over to the part of its starfield that has concepts related to Bali, Singapore and Lisbon, and spits out something similar to what the human trainer wrote.
        4. "Notice that this is not thinking. The LLM is doing autocomplete, but using this ‘arrow in the starfield’ property to give you very good, plausible-sounding, novel answers.
        5. "But because it writes so eloquently, and answers you like a human would, you think that it’s actually intelligent and sentient. I suppose you could say that it is ‘intelligent’ (by some definition of ‘intelligent’) but it is not a person. It doesn’t understand concepts the way a human does. What it is relying on is some complex version of this ‘arrow in a starfield’ property.
        6. "You may get better answers by constraining it to a smaller set of documents. So if you give it a bunch of papers, and ask it for themes or a summary of those papers, it may give you better answers than if you assumed those papers were in its original training corpus.

        "And that’s it."

- [OpenAI Realizes It Made a Terrible Mistake](https://futurism.com/openai-mistake-hallucinations): "In a [paper](https://arxiv.org/abs/2509.04664) published last week, a team of OpenAI researchers attempted to come up with an explanation. They suggest that large language models hallucinate because when they're being created, they're incentivized to guess rather than admit they simply don't know the answer. ... In simple terms, in other words, guessing is rewarded — because it might be right — over an AI admitting it doesn't know the answer, which will be graded as incorrect no matter what. As a result, through "natural statistical pressures," LLMs are far more prone to hallucinate an answer instead of "acknowledging uncertainty.""
- [Hallucinations getting worse as AI models get more capable](https://futurism.com/ai-industry-problem-smarter-hallucinating)

## Tools

* [Lovable](https://lovable.dev/): Create apps and websites by chatting with AI
* ChatGPT-5

    - https://futurism.com/gpt-5-disaster
    - [ChatGPT Is Blowing Up Marriages as Spouses Use AI to Attack Their Partners](https://futurism.com/chatgpt-marriages-divorces)

## Reading

* [Himanshu](https://www.linkedin.com/posts/himanshu1707_generativeai-journey-through-paperbacks-activity-7357857323756761088-elA4/):

    1. *Natural Language Processing with Transformers*: Start with a thorough understanding of Transformers architecture and it's ecosystem through HuggingFace with Lewis Tunstall Leandro von Werra Thomas Wolf . Personally, There cannot be a better starting point. MUST follow their blogs.
    2. *Build a Large Language Model (From Scratch)*: Build your own Decoder Transformer(Architecture for "almost" all modern LLMs) from scratch with Sebastian Raschka, PhD . MUST follow his blogs too for the latest updates. Also, lucky he keeps his GitHub repo updated.
    3. Get acquainted with the GenerativeAI ecosystem with Jay Alammar Maarten Grootendorst building LLM pipelines for various tasks and learning nitty gritty details of Fine-Tuning and PEFT. *Hands-On Language Models*
    4. Explore *Generative AI on AWS* with Chris Fregly Antje Barth Shelbee Eigenbrode for an enterprise level challenges.
    5. Dive into the beauty of engineering a GenAI Application with *AI Engineering* by Chip Huyen . It will level you up to think from the whole system perspective.
    6. *Build Generative AI Services with FastAPI* with Ali Parandeh, CEng . A very practical book to knot all you have learnt and will help you in building a GenAI system.

* [LangGraph101: Let's build a deep research agent](https://towardsdatascience.com/langgraph-101-lets-build-a-deep-research-agent/)

## Definitions

### [Expert Systems](/tags/expert%20system.html)/[Rules Engines](/tags/rules.html)

* [Wikipedia](https://en.wikipedia.org/wiki/Expert_system)

### Fuzzy Logic

* [Wikipedia](https://en.wikipedia.org/wiki/Fuzzy_logic)
* Tutorials: ["What is Fuzzy Logic"](https://www.guru99.com/what-is-fuzzy-logic.html) | ["Fuzzy Logic Explained: Master Class"](https://www.masterclass.com/articles/fuzzy-logic)
* [A Practical Introduction to Fuzzy Logic Using LISP](https://www.researchgate.net/publication/283225230_A_Practical_Introduction_to_Fuzzy_Logic_using_LISP)

Java:

- https://jfuzzylogic.sourceforge.net/
- https://github.com/sorend/fuzzy4j
- https://github.com/pcingola/jFuzzyLogic
- https://commons.apache.org/sandbox/commons-text/jacoco/org.apache.commons.text.similarity/FuzzyScore.java.html
- https://mvnrepository.com/artifact/com.github.cschen1205/java-fuzzy-logic/1.0.1

### Natural Language Processing

* [You Don't Need Backpropagation To Train Neural Networks Anymore](https://ai.gopubby.com/you-dont-need-backpropagation-to-train-neural-networks-anymore-e989d75564cb)
* [Wikipedia](https://en.wikipedia.org/wiki/Natural_language_processing)
* [HBR: "The Power of Natural Language Processing"](https://hbr.org/2022/04/the-power-of-natural-language-processing)
* ["Natural language processing: an introduction"](https://academic.oup.com/jamia/article/18/5/544/829676)
* ["Natural language processing: an annual review" (2003)](https://strathprints.strath.ac.uk/2611/1/strathprints002611.pdf)
* ["Advances in natural language processing"](https://nlp.stanford.edu/~manning/xyzzy/Hirschberg-Manning-Science-2015.pdf)
* ["Google Launched LangExtract, a Python Library for Structured Data Extraction from Unstructured Text"](https://www.infoq.com/news/2025/08/google-langextract-python/)

### Natural Language Programming

* [Extract, Edit, Apply](https://githubnext.com/projects/extract-edit-apply/)
* [A design pattern for AI](https://dsyme.net/2025/02/12/extract-edit-apply/)
* [On natural language programming](https://dsyme.net/2025/08/27/on-natural-language-programming/)
* [Why Kind of Programming is Natural Language Programming?](https://dsyme.net/2025/09/02/what-kind-of-programming-is-natural-language-programming/)

### [Large Language Models (LLMs)](/ai/llm/)

An advanced artificial intelligence (AI) system, built on deep learning and transformer architectures, that is pre-trained on massive amounts of text data to understand, process, and generate human-like language. LLMs learn to predict the next word in a sequence, enabling them to perform tasks like text generation, translation, summarization, and responding to complex queries, though they are not perfect oracles and can generate incorrect information or exhibit bias. 

* ["On the Biology of a Large Language Model"](https://transformer-circuits.pub/2025/attribution-graphs/biology.html): "We investigate the internal mechanisms used by Claude 3.5 Haiku — Anthropic's lightweight production model — in a variety of contexts, using our circuit tracing methodology."

### [Small Language Models (SLMs)](/ai/slm/)

An AI model designed to handle specific tasks, using fewer parameters and less computational power than a large language model (LLM). This efficiency makes SLMs faster to train, more accessible, and suitable for deployment on devices with limited resources or for performing specialized functions, such as data extraction from documents, language translation, or specific conversational agents. In terms of size, SLM parameters range from a few million to a few billion, as opposed to LLMs with hundreds of billions or even trillions of parameters. Parameters are internal variables, such as weights and biases, that a model learns during training. These parameters influence how a machine learning model behaves and performs.

### [Retrieval Augmented Generation (RAG)](/ai/rag)

* [Wikipedia: Prompt Engineering - Retrieval Augmented Generation](https://en.wikipedia.org/wiki/Prompt_engineering#Retrieval-augmented_generation)
* ["Cognita: An Open Source Framework for Building Modular RAG Applications"](https://www.marktechpost.com/2024/05/27/cognita-an-open-source-framework-for-building-modular-rag-applications/)

### AI Agent Knowledge Base

* [Anatomy of an AI Agent Knowledge Base](https://www.infoworld.com/article/4091400/anatomy-of-an-ai-agent-knowledge-base.html)

### Coding Assistants

* [Create a Coding Assistant with StarCoder](https://huggingface.co/blog/starchat-alpha)
* ["How to use GPT as a natural language to SQL query engine"](https://www.infoworld.com/article/3700858/how-to-use-gpt-as-a-natural-language-to-sql-query-engine.html)
* ["Who owns the code?"](https://leaddev.com/software-quality/github-copilot-make-commits): "This shift raises an important question: who is accountable when something goes wrong – Copilot, the reviewer, or someone else?Rajesh Jethwa, CTO of software engineering consultancy Digiterre, describes this issue as a “minefield”, because there are a number of entities involved in creating the code. First, there are the providers of the models themselves, such as OpenAI or Anthropic. It is currently unclear whether these providers own the code generated by their models. Second, there are the authors of the code used to train the model. There are still questions around whether they have any claim to ownership of the resulting code, given the provenance of the training data. Third, there are employees and the organizations they work for. Typically, when an employee creates code as part of their job, the organization owns that code. However, it remains uncertain whether the organization or the individual employee should bear responsibility for the code that is produced with the help of a coding assistance."

### Generative AI

* https://www.kdnuggets.com/generative-ai-a-self-study-roadmap
* ["Godot isn't making it"](https://www.wheresyoured.at/godot-isnt-making-it/): "What if what we're seeing today isn't a glimpse of the future, but the new terms of the present? What if artificial intelligence isn't actually capable of doing much more than what we're seeing today, and what if there's no clear timeline when it'll be able to do more? What if this entire hype cycle has been built, goosed by a compliant media ready and willing to take career-embellishers at their word? (March 2024) The reason I'm repeating myself is that it's important to note how obvious the problems with generative AI have been, and for how long."
* [Generative AI exists because of the transformer](https://ig.ft.com/generative-ai/)
* ["Stable Diffusion in Java (SD4J) Enables Generating Images with Deep Learning"](https://www.infoq.com/news/2023/12/stable-diffusion-in-java/)
* [Stable Diffusion in C#](https://github.com/cassiebreviu/StableDiffusion/) (mentioned in the SD4J article)

## [Machine Learning](/ai/machine-learning)

* [10 Github Repositories to Master Reinforcement Learning](https://www.kdnuggets.com/10-github-repositories-master-reinforcement-learning)
* [Machine Learning for Software Engineering](https://github.com/saltudelft/ml4se): A curated list of papers, theses, datasets, and tools related to the application of Machine Learning for Software Engineering.
* [Adversarial Machine Learning: A Taxonomy and Terminology of Attacks and Mitigations](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-2e2023.pdf)
* [A Brief Introduction to Machine Learning for Engineers](https://arxiv.org/pdf/1709.02840.pdf) - Osvaldo Simeone (PDF)
* [A Brief Introduction to Neural Networks](http://www.dkriesel.com/en/science/neural_networks)
* [A Comprehensive Guide to Machine Learning](https://www.eecs189.org/static/resources/comprehensive-guide.pdf) - Soroush Nasiriany, Garrett Thomas, William Wang, Alex Yang (PDF)
* [A Course in Machine Learning](http://ciml.info/dl/v0_9/ciml-v0_9-all.pdf) (PDF)
* [A First Encounter with Machine Learning](https://web.archive.org/web/20210420163002/https://www.ics.uci.edu/~welling/teaching/ICS273Afall11/IntroMLBook.pdf) - Max Welling (PDF) *(:card_file_box: archived)*
* [A Selective Overview of Deep Learning](https://arxiv.org/abs/1904.05526) - Fan, Ma, and Zhong (PDF)
* [Algorithms for Reinforcement Learning](https://sites.ualberta.ca/~szepesva/papers/RLAlgsInMDPs.pdf) - Csaba Szepesvári (PDF)
* [An Introduction to Statistical Learning](https://web.stanford.edu/~hastie/ISLR2/ISLRv2_website.pdf) - Gareth James, Daniela Witten, Trevor Hastie and Robert Tibshirani (PDF)
* [Approaching Almost Any Machine Learning Problem](https://github.com/abhishekkrthakur/approachingalmost) - Abhishek Thakur (PDF)
* [Bayesian Reasoning and Machine Learning](http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.HomePage)
* [Deep Learning](http://www.deeplearningbook.org) - Ian Goodfellow, Yoshua Bengio and Aaron Courville
* [Deep Learning for Coders with Fastai and PyTorch](https://github.com/fastai/fastbook) - Jeremy Howard, Sylvain Gugger (Jupyter Notebooks)
* [Deep Learning with PyTorch](https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf) - Eli Stevens, Luca Antiga, Thomas Viehmann (PDF)
* [Dive into Deep Learning](http://d2l.ai)
* [Explorations in Parallel Distributed Processing: A Handbook of Models, Programs, and Exercises](https://web.stanford.edu/group/pdplab/pdphandbook) - James L. McClelland
* [Foundations of Machine Learning, Second Edition](https://mitpress.ublish.com/ereader/7093/?preview=#page/Cover) - Mehryar Mohri, Afshin Rostamizadeh, Ameet Talwalkar
* [Free and Open Machine Learning](https://nocomplexity.com/documents/fossml/) - Maikel Mardjan (HTML)
* [Gaussian Processes for Machine Learning](http://www.gaussianprocess.org/gpml/)
* [IBM Machine Learning for Dummies](https://www.ibm.com/downloads/cas/GB8ZMQZ3) - Judith Hurwitz, Daniel Kirsch
* [Information Theory, Inference, and Learning Algorithms](http://www.inference.phy.cam.ac.uk/itila/)
* [Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/) - Christoph Molnar
* [Introduction to CNTK Succinctly](https://www.syncfusion.com/ebooks/cntk_succinctly) - James McCaffrey
* [Introduction to Machine Learning](http://arxiv.org/abs/0904.3664v1) - Amnon Shashua
* [Keras Succinctly](https://www.syncfusion.com/ebooks/keras-succinctly) - James McCaffrey
* [Learn Tensorflow](https://bitbucket.org/hrojas/learn-tensorflow) - Jupyter Notebooks
* [Learning Deep Architectures for AI](https://mila.quebec/wp-content/uploads/2019/08/TR1312.pdf) (PDF)
* [Machine Learning](http://www.intechopen.com/books/machine_learning)
* [Machine Learning for Data Streams](https://moa.cms.waikato.ac.nz/book-html/) - Albert Bifet, Ricard Gavaldà, Geoff Holmes, Bernhard Pfahringer
* [Machine Learning from Scratch](https://dafriedman97.github.io/mlbook/) - Danny Friedman (HTML, PDF, Jupyter Book)
* [Machine Learning, Neural and Statistical Classification](http://www1.maths.leeds.ac.uk/~charles/statlog/)
* [Machine Learning with Python](https://www.tutorialspoint.com/machine_learning_with_python) - Tutorials Point (HTML, [PDF](https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_tutorial.pdf))
* [Mathematics for Machine Learning](https://gwthomas.github.io/docs/math4ml.pdf) - Garrett Thomas (PDF)
* [Mathematics for Machine Learning](https://mml-book.github.io) - Marc Peter Deisenroth, A Aldo Faisal, and Cheng Soon Ong
* [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com)
* [Practitioners guide to MLOps](https://services.google.com/fh/files/misc/practitioners_guide_to_mlops_whitepaper.pdf) - Khalid Samala, Jarek Kazmierczak, Donna Schut (PDF)
* [Probabilistic Models in the Study of Language](http://idiom.ucsd.edu/~rlevy/pmsl_textbook/text.html) (Draft, with R code)
* [Python Machine Learning Projects](https://www.digitalocean.com/community/books/python-machine-learning-projects-a-digitalocean-ebook) - Lisa Tagliaferri, Brian Boucheron, Michelle Morales, Ellie Birkbeck, Alvin Wan (PDF, EPUB, Kindle)
* [Reinforcement Learning: An Introduction](http://incompleteideas.net/book/RLbook2020.pdf) - Richard S. Sutton, Andrew G. Barto (PDF)
* [Speech and Language Processing (3rd Edition Draft)](https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf) - Daniel Jurafsky, James H. Martin (PDF)
* [The Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/) - Trevor Hastie, Robert Tibshirani, and Jerome Friedman
* [The LION Way: Machine Learning plus Intelligent Optimization](https://intelligent-optimization.org/LIONbook/lionbook_3v0.pdf) - Roberto Battiti, Mauro Brunato (PDF)
* [The Mechanics of Machine Learning](https://mlbook.explained.ai) - Terence Parr and Jeremy Howard
* [The Python Game Book](https://web.archive.org/web/20210308080726/https://thepythongamebook.com/en%3Astart) - Horst Jens *(:card_file_box: archived)*
* [Top 10 Machine Learning Algorithms Every Engineer Should Know](https://www.dezyre.com/article/top-10-machine-learning-algorithms/202) - Binny Mathews and Omair Aasim
* [Understanding Machine Learning: From Theory to Algorithms](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning) - Shai Shalev-Shwartz, Shai Ben-David
* [You Don't Need Backpropagation To Train Neural Networks Anymore](https://ai.gopubby.com/you-dont-need-backpropagation-to-train-neural-networks-anymore-e989d75564cb)

### Semantic Entity Resolution (Knowledge Graphs) (?)

* [The Rise of Semantic Entity Resolution](https://towardsdatascience.com/the-rise-of-semantic-entity-resolution/)

