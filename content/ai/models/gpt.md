title=OpenAI gpt-oss
tags=ai, model, llm
summary=AI model.
~~~~~~

[Website](https://openai.com/) | [GitHub](https://github.com/openai/gpt-oss) | [HuggingFace](https://huggingface.co/openai/) | [Guides](https://developers.openai.com/cookbook/topic/gpt-oss)

Why should you use gpt‑oss‑120b:

* **Excellent performance.** gpt‑oss‑120b matches or surpasses o4-mini on core benchmarks like AIME, MMLU, TauBench, and HealthBench (even outperforms proprietary models like OpenAI o1 and GPT‑4o).

* **Efficient and flexible deployment.** Despite its size, gpt‑oss‑120b can run on a single 80GB GPU (e.g., NVIDIA H100 or AMD MI300X). It's optimized for local, on-device, or cloud inference via partners like vLLM, llama.cpp and Ollama.

* **Adjustable reasoning levels.** It supports low, medium, and high reasoning modes to balance speed and depth.

    * Low: Quick responses for general use.
    * Medium: Balanced performance and latency
    * High: Deep and detailed analysis.

* **Permissive license.** gpt‑oss‑120b is released under the Apache 2.0 license, which means you can freely use it for commercial applications. This makes it a good choice for teams building custom LLM inference pipelines.

## Model instances

### [`gpt-oss-120b`](http://huggingface.co/openai/gpt-oss-120b)

Our most advanced powerful open model designed for complex tasks, deeper context understanding, and enhanced reasoning capabilities.

### [`gpt-oss-20b`](http://huggingface.co/openai/gpt-oss-20b)

A versatile, efficient open-source language model ideal for a wide range of applications, from conversational AI to creative content generation.

## Reading

### Articles

- [The Best Open-Source LLMs in 2026](https://www.bentoml.com/blog/navigating-the-world-of-open-source-large-language-models)
