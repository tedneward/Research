title=Quit
tags=reading, thinking, philosophy, psychology
summary=Notes from the book.
~~~~~~

*(by Annie Duke, Penguin Random House, ISBN 9780593544020)*

# Prologue: The Gaffed Scale
Muhammad Ali: GOAT, and yet didn't know when to quit

**Grid vs Quit** We view grit and quit as opposing forces. While grit is a virtue, quit is a vice. Some goals are just not reachable, no matter how hard you continue. We ought not to confuse hindsight with foresight, which is what these aphorisms do. *(Survivor bias)* Success does not lie in sticking to things; it lies in picking the right thing to stick to and quitting the rest.

**Wrapped in Euphemism.** Lindsey Vonn: quit, but then said "I'm not giving up! I'm just starting a new chapter." The idea of quitting is such a bitter pill to swallow that we have to take it with a spoonful of sugar, or in this case, a spoonful of euphemism, the most famous of which is "pivot." We ought to stop thinking that we need to wrap the idea of quitting in bubble wrap. When it comes to quitting, the scale is gaffed (butcher's thumb on the scale to cheat customers).

**Science Says.** The book *Grit* is interpreted to mean "Never quit" but that's misinterpretation. She has herself written about the importance of trying lots of things (which requires that you quit lots of other things) to find the thing you want to stick with. There is a rich universe of science studying the human tendency to persevere *too long*, particularly in the face of bad news. Sunk cost, status quo bias, loss aversion, escalation of commitment, and so on. Kahneman's and Thaler's work. Science is telling us every day, we tend to stick to things too long in the face of signals that we ought to quit.

# Section I: The Case for Quitting

## Ch 1: The Opposite of a Great Virtue is Also a Great Virtue
**The Invisible Men at the Top of the World.** Mt Everest: a place where people really should learn to quit sooner. Three climbers: Dr Stuart Hutchison, Dr John Taske, Lou Kasischke. Part of a commercial guided expedition of Everest. Expedition leader stressed importance of having strictly-observed turnaround times (return to camp if you've not yet reached your destination) for each day's climb up the mountain. (Eight times more people die on Everest on the way down than on the way up.) Turnaround times are there to prevent people from making poor decisions to keep going when they're in the shadow of the summit, building into a climbing plan three critical concepts:

1. persistence is not always a virtue
2. making a plan for when to quit should be done long before you are facing the quitting decision
3. the turnaround time is a reminder that the real goal in climbing Everst is not to reach the summit, but to return safely to the base of the mountain

*(Simple Rules!)*

Hutchison, Taske, Kasischke were part of one of three expeditions, making the climb too crowded. Trio got stuck, with expedition leader, behind a group of incompetent climbers. At 11:30am, Hutchison called a meeting, realized that turnaround time was 1pm, and they wouldn't make it. Turned around. Made it safely back to the camp. Rest of the group was well-documented (book *Into Thin Air*, documentary *Everest*, 2015 film *Everest*), expedition leader Hall (who set the turnaround time!) and four others who reached the summit died on various parts of their descent back. But we don't know the Hutchison/Taske/Kasischke trio, because we tend to think about only one side of the human response to adversity (the ones who go for it). Even in this life-or-death situation, where quitting is the right decision, we don't remember the quitters at all.

**Quitting is a Decision-Making Tool.** Grit and quit are two sides of the same exact decision; you can't decide one thing without deciding the other. Grit is what gets you up the mountain, but quit is what tells you when to come down. ***"If I had to skill somebody up to get them to be a better decision-maker, quitting is the primary skill I would choose, because the option to quit is what allows you to react to a changing landscape."*** Any decision is made under some degree of uncertainty, stemming from two sources:

1. The world is stochastic: luck makes it difficult to predict exactly how things will turn out, at least in the short run. We operate not with certainties but with probabilities.
2. When we make decisions, we don't have all the facts.

When you take all these aspects of uncertainty together, it makes decision-making hard. But, after you've set out on a particular course of action, ***new information will reveal itself to you***. Feedback. Quitting is the tool that allows you to keep from being paralyzed by uncertainty or stuck forever in every decision you make. Quitting is what allows companies to maximize speed, experimentation, and effectiveness in highly uncertain environments.

Richard Pryor--greatest comedian ever--would routinely do shows at the Comedy Store on Sunset Strip with nothing prepared beyond "a couple of ideas" or "one or two jokes at the most" and bomb. The next night, he'd drop everything that didn't work--nearly the whole set--and expand on whatever got a titter. At the end of 30 days, he had 40 minutes of incredible material. *(OODA! He had a freakin 24-hour OODA loop!)*

**The Siren Song of Certainty.** Uncertainty is an impediment to making good decisions about quitting. Only one choice--the choice to persevere--lets you (eventually) find out the answer. The desire for certainty is the siren song calling us to persevere, because perseverance is the only path to avoiding the ambiguity of not knowing how it all turned out.

**The Super Bowl is a Corporate Graveyard.** The list of Super Bowl advertisers in Tom Brady's football career who've failed is long and impressive: AOL, Blockbuster, Circuit City, CompUSA, Gateway, Radio Shack, Sears. Super Bowl ads are big and expensive--if you could afford one, you were a big, successful company. Each couldn't maintain their success--the scale must be gaffed against quitting not just for individuals but for businesses as well. ***The road to sustained profitability for a business is not only about sticking to a strategy or business model, it is also about surveying and reacting to the changing landscape.***

**"Know When to Hold 'Em, Know When to Fold 'Em": But Mostly, Fold 'Em.** Three of the four things from Kenny Rogers' lyric are about quitting. When it comes to cutting your losses at the poker table, he "got it". Optimal quitting might be the most important skill separating great poker players from amateurs. Top poker players are know when to fold 'em: Pros play a mere 15% to 25% of the two-card starting combinations they are dealt in Texas Hold 'Em. Amateurs stick with over half. ***To be good at the game you ahve to learn to live with the idea that you folded some hands that might've won.*** Quitting a game is a decision fraught with uncertainty because it is never clear exactly why you are losing--you could be playing really well but losing because of an unlucky run of cards. In other words, if you want to glame your losses on luck and keep playing, you can always find a way to do that. Quitting a game when you're losing is the only way to guarantee you won't get those chips back in that game, which makes quitting when you are losing difficult. *(Again, here's the power of a stopping rule: Take the emotion and ego out of the decision by creating the stopping rule before it becomes an issue.)*

**Summary:**

* We tend to celebrate people who respond to adversity by soldiering on. The quitters, in comparison, are invisible.
* If we don't notice the decision-making of the quitters, it's hard to learn from them.
* Quitting a course of actio is sometimes the best way to win in the long run, whether you're cutting your losses at the poker table or getting to climb another day.
* Quit and grit are two sides of the exact same decision.
* Decision-making in the real world requires action without complete information. Quitting is the tool that allows us to react to new information that is revealed *after* we make a decision.
* Sticking with a course of action is the only way to find out for sure how it will turn out. Quitting requires being okday with not knowing what might have been.
* Having the option to quit helps you to explore more, learn more, and ultimately find the right things to stick with.

## Ch 2: Quitting on Time Usually Feels Like Quitting Too Early

In 2002 Stuart Butterfield built *Game Neverending*, a cooperative game, and in 2004 it failed due to lack of funding in post-dot-com-crash environment. They salvaged one feature, an inventory of objects the players accumulated, represented by a shoebox of photos, which became Flickr, which within a year they sold to Yahoo for $25m. Butterfield left Yahoo in 2008 and created a new game, *Glitch*, secured a bunch of funding (due to Flickr's rep) and released it in 2011; it looked amazing, and by Nov 2012, it had a devoted following of 5,000 users playing 20+ hrs/week. Problem: paid users were less than 5% of the user base, the rest having done the free sign-up; over 95% of new users played *Glitch* for less than seven minutes and never returned. Made a major PR push, yet after a particularly good push, Nov 12, Butterfield sent an email to investors: "I woke up this morning with the dead certainty that Glitch was over." He was able to peek into the future, and saw that in the range of possible outcomes, the probability was too high that the game would end up being a money pit. The math of the conversion rate just didn't work. "I think I knew this six weeks ago and I mistook denial for prudence (in the sense of making sure that we didn't give up too early). But there are just too many things in the 'against' column."  This freed him and the company to work on a different product: the "Searchable Log of All Conversation and Knowledge", aka Slack.

**Quit While You Still Have a Choice.** ***Quitting on time wil usually feel like quitting too early.*** Making good decisions about quitting requires mental time travel since the worst time to make a decision is when you're in it. That's when you are in the present, facing down the decision whether or not to cut your losses, unable to see past what is happening right now. When we do think about the future, we are often considering our hopes, our goals, our ambitions, and that optimism means that too often we allow a disastrous future to hurtle toward us, noticing it only as it's arriving on our doorstep. There is a well-known heuristic in management consulting that "the right time to fire someone is the first time it crosses your mind". But since this is a decision made under uncertainty, we tend to persist too long.

**Thinking in Expected Value.** To get the stick-or-quit decision right, you need to make an educated guess at the probability that things will go your way and the probability that things will go against you in order to figure out if the good stuff will occur enough of the time to warrant continuing on the same path. You need to think in Expected Value (EV). EV helps you answer two questions:

1. it tells you whether any option you are considering is going to be, on balance, positive or negative for you in the long run.
2. it allows you to compare different options to figure out which is the better choice, where "better choice" is the one that carries the highest expected value.

To determine the EV for any course of action, you start with identifying the range of reasonably possible outcomes, each of which will have some probability of occurring. If you multiply the probability of the outcome (p) with the outcome's good-or-bad (o), and add that all together, you get the EV. Example: fair coin flip (.5 heads, .5 tails) where heads = +$100, tails = -$50. Heads `p * o` is +$100 * .5 = +$50, Tails `p * o` is -$50 * .5 = -$25, EV is (+$50 + -$25), or +$25, or a positive EV. Example 2: Unfair coin flip, heads +$50 at p 0.9 (+$45) vs tails -$100 at p 0.1 (-$10), EV is +$35. Example 3: heads +$100,000 at p 0.01 (+$1,000), tails -$100 at p 0.99 (-$99), EV = +$901. *(All of this assumes we get 100 coin flips, though--if it's only one flip, then the decision-making changes here somewhat, I would think? I think Duke makes a subtle allowance for this: "Of course, that's a much riskier bet than the other two bets. Managing risk is the subject of many other books, but not this one.")*

Next, compare the EV for each option you might be considering. "If I were to switch and do something else, would that have a higher EV than the thing I'm currently doing?" Winning poker players aren't thinking about trying to win a single hand, come what may--they know while any two cards can win, only some hands can win enough of the time to make them worth pursuing. They are making decisions based on whether playing or folding will have the greater EV.

**Quitting Decisions are Expected-Value Decisions.** 2001: Duke gets an email from a reader who wanted help working through a decision about whether to quit her job. Duke asks, "A year from now, if you stay, what's the probability that you're going to be unhappy at the end of that year?" 100%. "A year from now, if you take the new job, what's the probability that you're going to be unhappy?" "Not sure" "Is it 100%?" "Definitely not." Enlightenment. Duke reframed the question as an EV problem.

**Time Travelers from the Past.** Thinking in expected value is a kind of mental time travel, propelling yourself into the future to glimpse the range of possible outcomes and take some reasonable guess at how likely each of them is. As a means to becoming a better quitter, this works in both directions: You can get the benefit of listening to a message *from the past*. Adm William McRaven, one of the world's most respected figures on military strategy, US foreign policy, and counterterrorism ops, is a longtime student of military history: "Probably three quarters of the books behind me (on his wall of bookshelves) are history books about battles that went well and battles that went wrong." When you are making a decision about whether to quit, you need to listen to those people from the past who are giving you important advice, whether its others or yourself.

**Flipping Coins.** 2013: Steven Levitt (author, *Freakonomics*) put up a website inviting visotrs to flip a virtual coin to help them decide quit-or-stick. They would register what they were stuggling with, among a variety of types of decisions, like "Should I quit my job or stay?" or "Should I leave my relationship?" or "Should I stay in college?". The site would assign one side of the decision to Heads, the other to Tails, and then randomly flip the coin. 20,000 people over the course of a year did this. Obviously, these people must have felt that the choice of quit-or-stick was so close, so 50-50, that flipping a coin to help them decide seemed like a reasonable option. Theoretically, they would be equally likely to be happier with either heads or tails, stick or quit. But this isn't what Levitt found. When he followed up with the coin flippers at 2 months and 6 months later, he discovered that for the big life decisions, people who quit were happier on average than people who stuck, whether they quit on their own or after the coin flip suggested quitting. ***While the decisions may have felt close to the people making them, they were actually not close at all. As judged by the participants' happiness, quitting was the clear winner.*** Because people were much happier when they quit what they considered a close decision, that shows that people are generally quitting too late. Levitt concluded, "The results of this paper suggest that people may be excessively caution when facing life-changing choices." Corollary: ***When people quit on time, it will usually feel like they are quitting too early, because it will be long before they experience the choice as a close call.***

**Jumping the Shark.** (*Happy Days* pop-culture reference.) We have an expectation that people ought to have seen in foresight what we can so easily see in hindsight. And when they don't, we can't believe how obtuse they are. That's the point of jumping the shark: It's mocking someone who doesn't quit on time, no matter that it's much harder to see the shark in foresight. But the sad thing is that as much as we make fun of people who quit too late, when someone does manage to quit on time, we mock them for quitting too early. That's the "quitting bind".

**The Quitting Bind.** Dave Chappelle quits *Chappelle's Show* in season 3, at the top of his game. Rumors swirled why. He quit because he could see two things: (1) he was unhappy in a future where he continued the show, and (2) he could see the shark: he was close to crossing the line between his audience laughing with him, and his audience laughing at him. Similar disappointment around Phoebe Waller-Bridge (2019) ending *Fleabag*, which in two seasons (2016, 2019) earned massive worldwide acclaim. Fans beg for more, despite Waller-Bridge's explanation that ending the series was consistent with the arc of the title character.

**Sunmmary:**

* Quitting on time usually feels like quitting too early.
* The hardest time to make a quitting decision is when you're in it.
* Our intuition is that quitting will slow down our progress. The reverse is actually true. If you walk away from something that is no longer worthwhile, that frees you up to switch to something that is more likely to help you achieve your goals--and you'll get there faster.
* When the time is objectively right to quit, nothing particularly dire will be happening right at that moment. Getting the timing right means looking into the future and seeing that the chances things will go your way are too slim.
* Thinking in expected value (EV) helps you figure out if the path you are on is worth sticking to. EV is not just about money. It can be measured in health, well-being, happiness, time, self-fulfillment, satisfaction in relationships, or anything else that affects you.
* If you feel like the choice between persevering and walking away is a close call, it's likely that quitting is the better choice.
* In hindsight, we can see when someone has waited too long to quit, and we tend ot be harsh in our judgment of those people. But when smoeone quits before it seems obvious to others, we mock them for quitting too early. That's the quitting bind.

## Ch 3: Should I Stay or Should I Go?

**Summary:**

* A key finding of prospect theory is *loss aversion*, the phenomenon whereby the emotional impact of a loss is greater than the corresponding impact of an equivalent gain.
* Loss aversion creates a preference for options associated with a lower chance of incurring a loss. It makes us risk averse.
* When we are in the gains, we have a tendency to quit too early in order to avoid the risk of giving those gains back. In other words, we like to quit while we're ahead.
* When we are in the losses, we become risk seekers. We want to keep going, hoping we can avoid ever having to realize the loss. Kahneman characterizes this as *sure-loss aversion*. In other words, we like to stick when we're behind.
* Quitting on time usually feels like quitting too early, and the *usually* part is *specifically when you're in the losses*.
* Retail investors show this pattern of quitting when they're ahead and sticking when they're behind.
* Even expert investors don't get their quitting decisions just right. They outperform on their buying decisions but underperform on their selling decisions.
* We naturally track and get feedback on the things we are doing. But once we quit something, we also quit keeping track of that course of action. This creates a problem with getting high-quality feedback, which in turn makes it hard to hone our quitting skills.

# Interlude I: Quitting When the World is Watching
2016: Alex Honnold prepares to free-solo-climb El Cap and a group of friends document the climb (which is them risking their lives, too). He quits. Comes back next June, crew reassembles, he successfully summits, free solo, and the documentary *Free Solo* is released in 2018, winning the Oscar for Best Documentary Feature. Had he not quit, he could easily have died, and the pressure was to stick.

# Section II: In the Losses

## Ch 4: Escalating Commitment
Harold Staw, his rise, his refusal to sell off his babies (his stores), and how he lost most of his money doing so. The mystery of it all is why: What blinded such a nimble, flexible decision-maker to the clear signals right in front of him? How could some of the same behavior that helped him thrive (through grit, determination, and stick-to-itiveness) end up causing his failure (through inflexibility, intractability, and maybe even some hubris)?

**Knee-Deep in the Big Muddy.** The very first sentence of one of the earliest and most influential academic papers identifying our tendency to persist in losing endeavors, even in the face of strong signals that we ought to quit, states very simply why such behavior is so confounding: “Intuitively, one would expect individuals to reverse decisions or to change behaviors which result in negative consequences.” The author of that seminal 1976 paper, “Knee-Deep in the Big Muddy: A Study of Escalating Commitment to a Chosen Course of Action,” is Harold and Shirley’s son, Barry Staw. He saw the US involvement in the Vietnam War as a living, breathing, high-stakes, slow-motion train wreck of an example of our inability to quit. Staw pointed to the revelation from the Pentagon Papers, a secret Department of Defense history of that war published over government objection by The New York Times and The Washington Post, that Undersecretary of State George Ball warned LBJ in 1965 of the inevitable entrapment in the conflict, “Once we suffer large casualties, we will have started a well-nigh irreversible process. Our involvement will be so great that we cannot—without national humiliation—stop short of achieving our complete objectives. Of the two possibilities I think humiliation would be more likely than the achievement of our objectives—even after we have paid terrible costs.” Staw’s central insight about escalation of commitment is that the phenomenon is not confined to matters like the Vietnam War, a complex geopolitical conflict with national pride wrapped up in it. His laboratory and field experiments show that whether it is on the level of an individual, an organization, or a governmental entity, when we’re getting bad news, when we are getting strong signals that we’re losing—signals that others plainly see—we don’t merely refuse to quit. We will double and triple down, making additional decisions to commit more time and money (and other resources) toward the losing cause, and we will strengthen our belief that we are on the right path.

**Waiting Until It Hurts.** Psychologists Jeffrey Rubin and Joel Brockner conducted an amusing experiment to answer two questions: How long will people wait for something that never arrives, and what price will they pay to continue waiting? It turns out people will wait a surprisingly long amount of time, and they will pay an amount that clearly exceeds the value of what they were waiting for. Escalation of commitment is costly. If the participants had walked away sooner, they would have made more. It may feel like quitting slows us down, but Rubin and Brockner show that it is persistence that is often the culprit. The work on escalation of commitment over the last forty-five years--in different laboratory experiments, field experiments, and explanations of commonly observed behavior--has shown that this type of entrapment in losing causes occurs across a variety of settings and circumstances.

**Summary:**
* When we are in the losses, we are not only more likely to stick to a losing course of action, but also to double down. This tendency is called escalation of commitment. 
* Escalation of commitment is robust and universal, occurring in individuals, organizations, and governmental entities. All of us tend to get stuck in courses of action once started, especially in the face of bad news. 
* Escalation of commitment doesn’t just occur in high-stakes situations. It also happens when the stakes are low, demonstrating the pervasiveness of the error.

## Ch 5: Sunk Cost and the Fear of Waste
2008 approval of bond measure for a high-speed rail system connecting LA and SF. Estimated completion in 2020, at a cost of $33b, generating yearly revenue of $1.3b by 2020, with an operating surplus of $370m, making it self-supporting and profitable thereafter. As of now, no part of that line is operational. Given the accuracy of the Authority’s past projections, there is no basis for believing that the revised estimates of 2029 (for initial service) or 2033 (for completion) are reasonably achievable. This shouldn’t be too surprising since they approved building the first segment in 2010 (twenty-five miles between Madera and Fresno), but they didn’t break ground for another five years. Why is this all taking so long? It turns out there are two titanic engineering obstacles to connecting the central, interior part of the planned route with the key metropolitan areas at either end of the state. First, they have to figure out a way to build track over or blast through the Tehachapi Mountains, which is necessary to connect Bakersfield with Los Angeles to its south. That issue pales in comparison to a second bottleneck, a portion of the Diablo Range known as the Pacheco Pass that stands between the Central Valley and the Bay Area to its north. Given where the project stands now, it’s a good bet that if the decision-makers had known then what they know now about how much the bullet train would cost and how long it would take, it wouldn’t have been approved in the first place. But having started the project, the Authority seems unwilling to quit and cut their losses.

**The Sunk Cost Effect.** Richard Thaler, in 1980, was the first to point to the sunk cost effect as a general phenomenon, describing it as a systematic cognitive error in which people take into account money, time, effort, or any other resources they have previously sunk into an endeavor when making decisions about whether to continue and spend more. A perfectly rational decision-maker would consider only the future costs and benefits in deciding whether to continue with a course of action. In other words, if continuing on has a positive expected value, a rational actor would persevere. If it has a negative expected value, they would quit. Forty years of experiments and fieldwork across a variety of domains show that people behave as Thaler hypothesized regarding sunk costs. In decisions about whether to move forward, they do take into account what they’ve already spent. They do this because they irrationally think that the only way to recover or justify the costs is if they continue on. ***Put simply, the sunk cost effect causes people to stick in situations that they ought to be quitting.***

There’s a simple elegance to Kahneman and Tversky’s proposition. You can see the decision error, free of complicating factors like how the participants got into the losing position or whether they realized their expected value was negative. In these experiments and those that followed, the math is made clear and transparent to the participants. ***This is not an error of calculation. This is an error of cognition.*** In a simple hypothetical like the concert, you can also see the error pretty clearly. It likely makes sense that a choice of how much you want to see the band versus how much you don’t want to spend hours in the cold and freezing rain shouldn’t depend on whether or how much you paid for the ticket. But this cognitive illusion is very strong. Just because you know it’s an error in theory doesn’t mean that you won’t fall for it when you are facing down these kinds of decisions.

**When "Public Works" Is an Oxymoron.** The sunk cost error’s fingerprints are all over the California bullet train. If most anyone were asked to start the project today as a new endeavor—knowing about the exploding costs, currently as much as $105 billion but likely to increase significantly, and how hard it will be to blast through those two mountain ranges—it seems obvious that the answer would be a hard no. In addition to the direct costs of the project, there is the issue of opportunity costs. Every dollar that California sinks into the project is a dollar that could otherwise be allocated to something that would create more value and a greater public good for the taxpayers whose money is funding the endeavor. But imagine how gutsy a politician would have to be to abandon the project, knowing they’re going to have to defend themselves against charges of having “wasted” more than $8 billion on a train that was never completed. The pressure to keep going to “recover” those costs is enormous. When it comes to these types of public works projects, sunk cost is a familiar refrain.

**Katamari.** There was a popular video game that came out in 2004 named *Katamari Damacy*. It was a silly game, strangely addictive, with a grandiose but simple plot. You control the actions of a tiny prince, whose father, the King of All Cosmos, gives him a katamari (Japanese for “clump”), a sticky ball you roll around different locations, picking up trash and debris off the floor, the ball growing bigger and bigger as it accumulates more stuff. Why are you on this mission? The king had gotten drunk and accidentally destroyed a bunch of stars and constellations. You have to grow the ball until it’s big enough to become a star to replace the ones the king destroyed. It’s a goofy plot, but no goofier than whatever is supposed to be motivating you to eat dots and fruit in Pac-Man or fit together block formations in Tetris. The katamari can’t roll over anything bigger than itself. If it does, the impact knocks some things off, making your ball even smaller. At the beginning, your katamari is only big enough to pick up things like ants, thumbtacks, and buttons. Running into a mouse can be a catastrophe. But as you successfully pick up debris, the ball gets bigger. Then you’re terrorizing the mouse. You’re rolling over batteries, plates of food, radios, shoes, pets. Cows, bears, sumo wrestlers, cars, monsters, buildings, islands, mountains. As one reviewer put it after listing some of the mundane little items, “25 minutes later the bloody thing is ripping rainbows out of the ground.” ***Like the katamari, rolling around collecting debris, which makes it grow in mass and collect more and even bigger debris, there is a self-reinforcing aspect to the sunk cost fallacy that we really need to watch out for.***

A relationship that’s not working out turns into a game of Katamari. Your friend complains about being in a bad relationship. If you ask, “Why don’t you just break up?” they’ll frequently say, “Because I’ve put so much time into trying to make this relationship work.” Sometimes, they’ll even say, “I put my heart and soul into it.” The more time they put in, the less likely they are to break it off, which leads to them investing more time to get it to work. That makes them even less likely to break up. And so on. No wonder that once you have this talk with a friend, you end up having it over and over again. Their dysfunctional relationship keeps rolling up mass—living arrangements, friends, pets, consumer purchases, property—until they’re ripping rainbows out of the ground.

**How Big Does the Katamari Grow?** In Barry Staw’s classic 1976 experiment, “Knee-Deep in the Big Muddy: A Study of Escalating Commitment to a Chosen Course of Action,” he set out to ask how much prior commitment to a course of action influences future decisions about whether to stick or quit. He discovered that the answer is a lot. Staw recruited groups of business school students who were tasked with individually deciding how a corporation should allocate certain R&D funds between two of its divisions. To help with the choice, the students were given ten years of historical financial performance about the company and the two divisions under consideration. The participants each had to make an all-or-nothing decision about which department should receive the $10 million in R&D funds, meaning they only had two options: allocate the entire $10 million to one division and give no funds to the other or vice versa. Given the data provided to the students, there were reasonable arguments for allocating the funds to either of the two divisions. While one division was more profitable, the other was growing more quickly. Indeed, the participants, who were all coming into this decision fresh, split about 50-50 on which division they chose. What Staw wanted to find out was whether this initial decision about which division got the funds would affect future allocation decisions, particularly once the participants learned their first choice turned out poorly. In other words, Staw was exploring whether people who carry a loss into a new allocation decision would be more likely to persist, continuing to direct funds to the same division they had previously sunk resources into. To answer that question, he gave all the students a simulation of the next five years of financial results for the company. Regardless of which option they directed the funds to, the additional data showed that the division they chose suffered from half a decade of stagnant sales and deepening losses, significantly underperforming the division they passed over. After being shown this performance data, the participants were then given a new budget of $20 million, which they could now allocate *proportionally* across the two divisions. Staw hypothesized that students receiving negative feedback on their first decision would *increase* their commitment to their original cause, favoring that same division in the second allocation. Indeed, that is what he found. The participants allocated, on average, over $13 million of the $20 million to the division that they originally directed the R&D funds to, and just under $7 million to the one they did not initially choose. To really hit the point home, he also had a separate group of participants come to the $20 million allocation fresh, as a new decision. They were shown the same financial results and informed of a $10 million R&D allocation five years earlier (by a since-departed financial officer) to the division that subsequently underperformed. In this case, they were not the ones who initially made the decision to sink the R&D funds into one division or the other. When these fresh participants allocated the $20 million proportionally across the two divisions, they gave an average of just $9 million to the division that received the prior funds, much less than the $13 million allocation by the participants carrying with them the sunk cost debris of having personally incurred the prior losses. Putting it into sharp focus, the participants responsible for the first, money-losing decision *directed nearly 50%* more of the $20 million to that same division, compared with others with the identical information and corporate history but no personal responsibility for prior policy.

**Mental Accounting.** There’s a saying among top poker players that poker is one long game. It’s a reminder that the particular hand they’re playing is not the last hand they’ll ever play or that any particular day that they’re playing is not the last day they’ll ever play. A poker player will play thousands upon thousands of hands over their lifetime, so in the grand scheme of things whether or not they lose one single hand of poker matters very little. What matters is that they’re maximizing their expected value over all those days and all those hands. That’s what they mean by one long game. This mantra is meant to help expert players overcome the sunk cost fallacy, expressed in poker as wanting to protect the money you’ve already invested in a single hand by not folding, or not wanting to quit a game when you’re in the losses. Of course, what applies to poker applies to life as well. ***We all need this kind of reminder because of a quirk in our mental accounting.*** 

When we start something, whether it’s putting money into the pot in a hand of poker, or starting a relationship or a job, or buying a stock, we open up a mental account. When we exit that thing, whether it’s folding a hand, or leaving a relationship or job, or selling the stock, we close that mental account. It turns out that we just don’t like to close mental accounts in the losses. If we’re losing in a hand of poker, we don’t want to fold because that means we have to realize the loss of the money we put in the pot. If we’re losing in a poker game, we don’t want to quit because it means that we have to leave with less money than we started with. If we’re in a relationship or a job, we don’t want to walk away because we’ll feel like we will have wasted or lost all the time and effort that we put in. Of course, that’s irrational. What really matters is maximizing your expected value across all the things you start, across all of your mental accounts. If you’re investing in a number of stocks, some are going to win and some are going to lose. What matters is whether you’re winning across your whole portfolio not whether any one investment is up or down. But that’s not how we naturally think. We don’t think about the whole portfolio of stocks we own. Each is associated with its own mental account that we don’t want to close out unless we are in the gains.

**The Hardest Cost to Bear.** ***The greater the sunk costs, the harder it becomes to quit.*** And the greatest cost is, of course, the loss of human life. That makes decisions about whether or when to exit a war heartbreakingly difficult. Retired four-star general Tony Thomas, commander of U.S. Special Operations Command (USSOCOM), served in Afghanistan on missions between 2001 and 2013 (except for a year when he served in the Iraq War). He attended many military funerals and gave an American flag to many gold star families. He described to me those humbling experiences and how those tragic losses amplify the types of sunk cost problems we all face, making it particularly difficult for a country to extricate itself from a war once it has started to incur those losses. On one occasion, a gold star mother, having just lost her son, gripped his hand and said, “Stay on this and finish it.” The general’s knees almost buckled. At that moment, he wanted to run through a wall for her. The unspoken message, never expressed at these funerals but which he felt was on the minds of all those grieving parents, was, “Tell me my child didn’t die in vain.”

**The Difference between Knowing and Doing.** *There are lots of intuitions people have about cognitive biases, including the sunk cost fallacy. One of the most common is that if you are educated on the topic and know about it, that will stop you from committing the error.* Jebbrey Rubin climbed 99 of the 100 highest peaks in New England, and was climbing the last one, Fort Mountain, in Maine. When the weather turned bad and a fog came in, his climbing partner decided to turn around. Jeffrey R. disagreed and continued climbing alone. His body was found several days later. He apparently fell to his death. Why am I telling you this story, so similar to some of the others? One person turns around. The other continues to go on, with tragic consequences. The Jeffrey R. in this story is Jeffrey Rubin, the same Jeffrey Rubin who, with Joel Brockner, studied the behavior of people waiting for a crossword puzzle dictionary that never came, and followed it up with an impressive and influential body of work on escalation of commitment right up to his death in 1995. If anybody understood the problem of being entrapped in a course of action, unable to cut your losses even in the face of clear signals that you ought to be quitting, it would have been him. Yet he became entrapped that day. This should be a warning to all of us. Don’t think that, just because you’ve read up to this point in the book or understand the sunk cost fallacy, this knowledge alone is going to help you overcome it. If Rubin was unable to quit, that should open our eyes to how hard it is for the rest of us. ***Knowing is not the same as doing.***

**You Can't Jedi Mind Trick Being Fresh to a Decision.** A lot of people who know about the sunk cost fallacy tell me they’ve come up with a solution. Essentially, regardless of the history they have with the decision, they ask themselves, “If I were approaching this decision fresh, would I want to enter into this course of action?” Does this Jedi mind trick actually work? We can, once again, look to Barry Staw for the answer. In one of the follow-ups to the “Big Muddy” experiment, Itamar Simonson and Staw asked participants to make a corporate decision about allocating marketing funds to two products, a nonalcoholic beer and a lite beer. The first decision was, again, an all-or-nothing choice of which product should receive an additional $3 million in marketing support. After making their choice and receiving a simulation of three years of results based on that choice, the participants made a second decision as to how to split another $10 million marketing budget between the two products. The investigators tested several possible ways of mitigating escalation of commitment to the product that received the initial $3 million in marketing funds. One of those ways was the Jedi mind trick, where they asked some of the participants to approach the decision fresh, specifically instructing them to do an analysis listing the pros and cons of allocating funds to each product going forward. Despite the instruction to look forward rather than backward when making this new decision, the participants made a similar allocation ($5.1 million) to the product they earmarked the original funds to as compared to those who made the same prior, losing decision but were not given instruction to just look forward. In contrast, participants who actually came to the second allocation fresh gave just $3.7 million to the product that lost money after receiving the earlier addition of marketing funds. The instruction to treat it as a new decision did practically nothing to reduce escalation of commitment. Just knowing about the sunk cost effect doesn’t help. ***The Jedi mind trick doesn’t help.***

**Summary:**

* The sunk cost effect is a cognitive illusion where people take into account resources they have previously sunk into an endeavor when making decisions about whether to continue and spend more.
* The sunk cost effect causes people to stick in situations that they ought to be quitting.
* When deciding whether to stick or quit, we are worried that if we walk away, we will have wasted the resources we have spent in the trying.
* You might be experiencing the sunk cost fallacy if you hear yourself thinking “If I don’t make this work I will have wasted years of my life!” or “We can’t fire her now, she’s been here for decades!” 
* Sunk costs snowball, like a katamari. The resources you have already spent make it less likely you will quit, which makes it more likely you will accumulate additional sunk costs, which makes it again less likely you will quit, and so on. The growing debris of your prior commitment makes it increasingly harder to walk away.
* We don’t like to close mental accounts in the losses.
* Knowing about the sunk cost effect doesn’t keep you from falling prey to it.
* You can’t trick yourself into not taking sunk costs into account by trying to view the situation as a new choice. Asking whether or not you would continue if the decision were a fresh one doesn’t mitigate the sunk cost effect the way you might intuitively think it would.

## Ch 6: Monkeys and Pedestals
Eric Teller is CEO of "X", an innovation labs subsidiary of Alphabet, though his actual job title is "Captain of Moonshots." X has become a famous incubator and developer of ideas in the nontraditional tradition of Bell Labs, Xerox PARC, and Thomas Edison’s laboratories. X’s mission is to build and launch technologies to “improve the lives of millions, even billions of people.” They’re specifically in the business of identifying and accelerating world-changing ideas. That means they reject plenty of good ideas because the change those ideas create would be too incremental for their mission. One of X’s slogans is “10x impact on the world’s most intractable problems, not just 10% improvement.” X takes a lot of big swings, knowing that most will be whiffs. Teller looks at each project as buying an option on the future. Like most options, you have to keep paying to hold it, in increasing amounts. To help X-ers become better quitters, Astro Teller has come up with a unique mental model that has been woven into the fabric of X: monkeys and pedestals.

Imagine that you’re trying to train a monkey to juggle flaming torches while standing on a pedestal in a public park. If you can achieve such an impressive spectacle, you’ve got a moneymaking act on your hands. Teller recognizes that there are two pieces to becoming successful at this endeavor: training the monkey and building the pedestal. One piece of the puzzle presents a possibly intractable obstacle in the way of success. And the other is building the pedestal. People have been building pedestals since ancient Greece and probably before. Over two-plus millennia, pedestals have been thoroughly figured out. You can buy one at a furniture store or a hardware store, or turn a milk crate upside down. The bottleneck, the hard thing, is training a monkey to juggle flaming torches. The point of this mental model is to remind you that there is no point building the pedestal if you can’t train the monkey. ***In other words, you ought to tackle the hardest part of the problem first.***

**Getting the Monkey Off Your Back.** Project Foghorn, X’s initiative to develop technology to convert seawater into fuel, offers an example of how the monkeys-and-pedestals mental model works. The first monkey would be proof of concept, but they already had that from the scientists they were partnering with whose recent work attracted their attention to the innovation. The second monkey was commercial viability. They would have to produce the fuel at a cost that was significantly lower than the current price per gallon for gasoline to get broad adoption in the market.

One of the beautiful things about the monkeys-and-pedestals mental model is that sometimes it helps you quit before you start. Years ago, X looked into developing what’s now known as a hyperloop, an experimental high-speed rail system. The concept was fine. Building the physical infrastructure wouldn’t be very hard from an engineering standpoint. The monkeys for the hyperloop to be viable were things like whether you could safely load and unload passengers or cargo, and whether you could get the system up to speed and get it to brake without incident. A couple hundred yards of track wouldn’t tell you anything about whether you could conquer those challenges. In fact, Teller and the team at X figured out that you would have to build practically the whole thing before you knew whether it worked. You would have to build a bunch of pedestals before you could find out if the monkeys were intractable. They quickly decided not to pursue it.

***One of Teller’s valuable insights is that pedestal-building creates the illusion of progress rather than actual progress itself.*** When you are doing something that you already know you can accomplish, you’re not learning anything important about whether the endeavor is worth pursuing. You already know you can build the pedestal. The problem is whether you can train the monkey. 

On top of that, Teller realizes that ***when you’re building pedestals, you are also accumulating sunk costs that make it hard to quit even as you find out that you may not be able to train the monkey to juggle those torches***. By focusing on the monkey first, you naturally reduce the debris you accumulate solving for something that’s, in reality, already solved. 

Teller also understands a subtler but no less important point, that ***we have a tendency, when we butt up against a monkey that is proving difficult to solve, to turn our attention to building pedestals rather than giving up***. We prefer that illusion of progress to having to quit and admit defeat.

> Figure out the hard thing first. Try to solve that as quickly as possible. Beware of false progress.

**Kill Criteria.** If we can identify in advance what the signals are that we should pay attention to and make a plan for how we will react to them, we can increase the chances that we’ll cut our losses when we ought to. Ask yourself, “What are the signs that, if I see them in the future, will cause me to exit the road I’m on? What could I learn about the state of the world or the state of myself that would change my commitment to this decision?” That list offers you a set of *kill criteria*, literally criteria for killing a project or changing your mind or cutting your losses. It’s one of the best tools for helping you figure out when to quit closer to on time. *(Stopping rules!)* Essentially, kill criteria create a precommitment contract to quit.

**Funnel Vision.** You can likely imagine lots of applications of kill criteria in your personal life. When you start dating someone, think ahead. What could be happening that would make you think that it was time to end the relationship? Or, in the case of a single date, what would make you want to end the date? You could do that with going to a particular college, picking a major, starting a career, or taking a job. An obvious and high-value application of kill criteria has to do with funnel management for a business’s sales function. A big problem for sellers is managing all the opportunities at the top of the funnel: Which do you pursue? And, once you’ve started pursuing a lead, when do you give up on it? It’s in a company’s interest to make sure its sellers are spending their time pursuing the highest-value opportunities, based on a combination of the probability of closing and the potential size of the contract.

(Story about creating kill criteria to help avoid spending sales time/resources on low-expected-value leads.) We tend to associate the idea of funnel management with sellers or investors. But every one of us has a funnel we are managing: the interests we can pursue, the classes we can take, the projects we can do at work, the jobs we can apply for, the people we can date. We all have to make these choices about which opportunities to pursue and which to skip or quit. As we’re making those choices, we want to spend as little time as possible on the things that aren’t worthwhile and as much time as possible on the things that are.

The good news about kill criteria is that you haven’t missed your chance to set them once you have already started an endeavor. At any point, no matter whether it comes to someone you are dating or a house you already own or an investment you are in or a college you are attending, you can think about some time frame in the future, imagine you are unhappy with your situation, and identify the benchmarks you will have missed or the signals you will be seeing that will tell you that you ought to walk away. You may not have set a stop-loss or take-gain when you bought a stock but you can set one now. After all, the present is always in advance of something.

**States and Dates.** The best quitting criteria combine two things: a state and a date. A state is just what it sounds like, an objective, measurable condition you or your project is in, a benchmark that you have hit or missed. A date is the when. Kill criteria, generally, include both states and dates, in the form of “If I am (or am not) in a particular state at a particular date or at a particular time, then I have to quit.” Or “If I haven’t done X by Y (time), I’ll quit.” Or “If I haven’t achieved X by the time I’ve spent Y (amount in money, effort, time, or other resources), I should quit.”

Admiral McRaven offered a unique, high-stakes application of this concept of states and dates when describing the planning for Operation Neptune Spear, the raid on Osama bin Laden. The operation was broken down into 162 phases. Each phase told you what state you would have to achieve to continue, and what state you might be in that would cause you to quit during that phase. Because this was all planned out in advance, it left McRaven, as he told me, with only about five command decisions he might have to make on the fly once the mission had commenced and they were already in it. He gave two examples of the criteria that would cause them to kill the mission. If at any point they fell an hour behind schedule, they would abort. Or, if they discovered that, at any time up to 50% of the way to bin Laden’s compound, they had been detected and compromised by the Pakistani government, they would turn around. If they were compromised beyond the 50% mark, that would be a command decision McRaven would have to make on the fly.

You can apply states and dates to relationships. If your goal is marriage (or an equivalent long-term commitment), then if your relationship partner hasn’t proposed (or accepted your proposal or otherwise demonstrated a long-term commitment) by a certain date, you should move on and find someone who is as excited about committing to you as you are to them. 

You can do the same for career advancement. If you’re working at an entry-level position that has some prospect for advancement, figure out as early as you can the interim milestones for those who succeed, whether it’s raises, or initial promotions, or additional responsibilities, or whatever is specific in that company or practice. Get information about when others who’ve succeeded got those signals on the way up and include those states and dates in your kill criteria.

**Better, Not Perfect.** When I was playing poker, I applied a bunch of kill criteria that helped me be a better quitter (of hands and of games). One example was a stop-loss. If I lost a certain amount, I would quit. This was especially important at the start of my career, because novice players are particularly poor at judging whether they’re losing due to their poor play or because of bad luck. (Take-gains don’t make sense in poker, so I didn’t employ that tool.) After turning pro, I still maintained a stop-loss. Elite poker players are still going to be worse at making quitting decisions when they’re in it, especially if they’re in it and losing. So, even after I gained experience and got a better understanding of the quality of my play and the short-term swings of luck, I still set loss limits. I also realized that I played better in sessions of six to eight hours or less, so I committed to quitting after I played that long. Because I was more aware of the importance of game conditions, I also committed to quit if the quality of the players in the game drastically changed in an unfavorable way as some players cashed out and new ones took their seats. Those kill criteria helped me to become better at quitting games. But was I perfect? Not even close.

Taken together, the monkeys-and-pedestals mental model and kill criteria help us overcome our aversion to closing accounts in the losses. First, they both get you to no faster, which naturally limits the losses that you have to absorb when you quit. And the less you are down, the easier it is to walk away. Second, when you set out clear kill criteria in advance and make a precommitment to walk away when you see those signals, you are just more likely to follow through, even when you are losing. Anytime you can make a decision about cutting your losses in advance, you’ll do better at closing those mental accounts.

**Summary:**

* Monkeys and pedestals is a mental model that helps you quit sooner.
* Pedestals are the part of the problem you know you can already solve, like designing the perfect business card or logo. The hardest thing is training the monkey.
* When faced with a complex, ambitious goal, (a) identify the hard thing first; (b) try to solve for that as quickly as possible; and (c) beware of false progress.
* Building pedestals creates the illusion that you are making progress toward your goal, but doing the easy stuff is a waste of time if the hard stuff is actually impossible.
* Tackling the monkey first gets you to no faster, limiting the time, effort, and money you sink into a project, making it easier to walk away. 
* When we butt up against a hard problem we can’t solve, we have a tendency to turn to pedestal-building rather than choosing to quit.
* Advance planning and precommitment contracts increase the chances you will quit sooner.
* When you enter into a course of action, create a set of kill criteria. This is a list of signals you might see in the future that would tell you it’s time to quit.
* Kill criteria will help inoculate you against bad decision-making when you’re “in it” by limiting the number of decisions you’ll have to make once you’re already in the gains or in the losses.
* In organizations, kill criteria allow people a different way to get rewarded beyond dogged and blind pursuit of a project until the bitter end.
* A common, simple way to develop kill criteria is with “states and dates:” “If by (date), I have/haven’t (reached a particular state), I’ll quit.”

# Interlude II: Gold or Nothing
Sasha Cohen's figure-skating career and the idea that quitting on something is quitting on ourselves, as in, our identity of ourselves.

# Section III: Identity and Other Impediments

## Ch 7: You Own What You've Bought and What You've Thought: Endowment and Status Quo Bias

## Ch 8: The Hardest Thing to Quit is Who You Are: Identity and Dissonance

## Ch 9: Find Someone Who Loves You but Doesn't Care About Hurt Feelings

# Interlude III: The Ants Go Marching... Mostly

# Section IV: Opportunity Cost

## Ch 10: Lessons from Forced Quitting

## Ch 11: The Myopia of Goals

